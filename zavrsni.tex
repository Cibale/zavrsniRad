\documentclass[times, utf8, zavrsni, numeric]{fer}
\usepackage{booktabs}
\usepackage{listingsutf8}
\usepackage[titletoc,page]{appendix}
\captionsetup[lstlisting]{position=bottom}
\addto\captionsenglish{%
  \renewcommand{\figurename}{Slika}%
  \renewcommand{\contentsname}{Sadržaj}
  \renewcommand{\appendixname}{Dodatak}
  \renewcommand\tablename{Tablica}
  \renewcommand\bibname{Literatura}
  \renewcommand{\lstlistingname}{Primjer}
}
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  captionpos=b,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
%\lstset{language=Java,
% basicstyle=\tiny\tt,
% showspaces=false,
% showstringspaces=false,
% breaklines=true
% }
\lstset{
    literate=%
    {ć}{{\'c}}1
    {č}{{\v{c}}}1
    {đ}{{\dj{}}}1
    {š}{{\v{s}}}1
    {ž}{{\v{z}}}1
    {Ć}{{\'C}}1
    {Č}{{\v{C}}}1
    {Đ}{{\DJ{}}}1
    {Š}{{\v{S}}}1
    {Ž}{{\v{Z}}}1
}
\begin{document}

% TODO: Navedite broj rada.
\thesisnumber{1337}

% TODO: Navedite naslov rada.
\title{Obrada podataka tehnologijom Apache Spark}

% TODO: Navedite vaše ime i prezime.
\author{Martin Matak}

\maketitle

% Ispis stranice s napomenom o umetanju izvornika rada. Uklonite naredbu \izvornik ako želite izbaciti tu stranicu.
\izvornik{Na ovoj stranici se nalazi izvornik.}

% Dodavanje zahvale ili prazne stranice. Ako ne želite dodati zahvalu, naredbu ostavite radi prazne stranice.
\zahvala{Zahvala - TODO \ldots :)}

\tableofcontents

\chapter{Uvod}
\section{Motivacija}
%Literatura: http://mob.hr/samsung-galaxy-s4-skrivene-mogucnosti-senzori-i-octa-5-benchmark/
Skoro pa svaka osoba danas posjeduje mobilni uređaj, a neke osobe posjeduju i više njih. Pametni mobilni uređaji postaju neizostavan dodatak svakog modernog čovjeka. Prošlo je vrijeme kada su mobilni uređaji jedino služili za pozive i SMS poruke. Današnji mobilni uređaji imaju puno više mogućnosti. Osim što je zadržana funkcionalnost uspostavljanja poziva i slanja poruka, postoji mogućnost povezivanja na internet, orijentaciju u prostoru, mjerenje brzine itd. Da bi sve te stvari bile moguće, većina današnjih mobilnih uređaja u sebi sadrži senzore koji su navedeni i opisani u tablici \ref{tbl:senzori}.

\begin{table}[htb]
\caption{Neki od senzora u današnjim mobilnim uređajima.}
\label{tbl:senzori}
\centering
\begin{tabular}{l p{8cm}}
\hline
Senzor & Opis \\
\hline
Akcelerometar & Elektromehanička komponenta koja mjeri sile ubrzanja. \\
Barometar & Mehanički senzor za mjerenje atmosferskog pritiska (na trenutnoj lokaciji uređaja).\\
Senzor svjetlosti & Mjeri intenzitet, tj. jačinu svjetlosti i uglavnom se nalazi s prednje strane uređaja, iznad ekrana. \\
Senzor blizine & U stanju prepoznati situacije kada mu neki objekt stoji u blizini - ovo omogućava automatske pozive prilikom primicanja telefona licu uz zaključavanje telefona da bi onemogućili slučajno prekidanje poziva uhom ili slično.\\
Senzor gestikulacije & Prepoznaje kretnje ruke tako što detektira infracrvene zrake koje se reflektiraju, odnosno omogućuje djelomično upravljanje telefonom bez doticanja ekrana.\\
Žiroskop & Uređaj koji se koristi za navigaciju i mjerenje kutne brzine.\\
Geomagnetski senzor & Mjeri okolno geomagnetsko polje za sve tri fizičke osi, odnosno služi kao kompas na mobilnim uređajima. \\
\emph{Hall Sensor} & Magnetski senzor zadužen za prepoznavanje je li  maska telefona zatvorena ili otvorena. \\
\hline
\end{tabular}
\end{table}

Pretpostavimo da je mobilni uređaj spojen na internet i da svakih nekoliko sekundi pošalje vrijednost koju u tom trenutku mjeri pojedini senzor. U samo jednom danu može se skupiti dosta podataka. A što kada to ne bi radili za jedan uređaj nego za sve izdane uređaje nekog modela? Količina podataka bi jako brzo narasla.

Kako količina podataka postaje sve veća, dolazimo do pojma \emph{Velika količina podataka} \engl{Big Data}. U današnje vrijeme postoji više podataka u digitalnom obliku nego što ih je ikada bilo. Jedan od zanimljivijih izazova je kako ih djelotvorno obraditi i zaključiti nešto iz toga, odnosno kako od te velike količine podataka doći do nekih pametnih zaključaka i nešto novo naučiti.

Tehnologija \emph{Apache Spark} je tehnologija otvorenog koda \engl{open source} koja omogućava pisanje programa za obradu podataka u tri programskih jezika: Java, Python i Scala. Dodatno, postoji i mogućnost interaktivnog rada. \\
U okviru ovog rada proučeni su neki djelovi ove tehnologije, razrađeno nekoliko konkretnih primjera obrade podataka te ostvarena programska rješenja koja obavljaju tu obradu koristeći tehnologiju \emph{Apache Spark}.

Svi primjeri su napisani u programskom jeziku Java.

\section{Osnovni gradivni elementi}
Tehnologija \emph{Apache Spark} je pisana u programskom jeziku Scala i izvršava se na \emph{Javinom virtualnom stroju} (engl. \emph{Java Virtual Machine}, kratica JVM). Instalacija na osobno računalo je objašnjena u dodatku \ref{ch:instalacijaSpark}. Opisi nekih direktorija i datoteka koje se dobiju instalacijom dani su u tablici \ref{tbl:installPackage}. Zanimljivo je spomenuti da postoji interaktivna ljuska \emph{Spark shell}, ali isključivo za programske jezike Python i Scala. Datoteke u direktoriju \emph{bin} služe upravo za to. Budući da je ovaj rad ograničen isključivo na programski jezik Java, a u ovom trenutku takva interaktivna ljuska još ne postoji, interaktivna ljuska nije detaljnije obrađena. Više informacija potražiti u \cite{learningSpark}.

\begin{table}[htb]
\caption{Dio datoteka i direktorija dobivenih instalacijom.}
\label{tbl:installPackage}
\centering
\begin{tabular}{l p{8cm}}
\hline
Datoteka ili direktorij & Opis \\
\hline
\emph{bin} & Sadrži izvršive datoteke koje se koriste za interaktivni rad s tehnologijom \emph{Apache Spark}.\\
\emph{core, streaming, python, ...} & Sadrži glavne komponente tehnologije. \\
\emph{README.md} & Sadrži kratke instrukcije za upoznavanje s tehnologijom.\\
\emph{examples} & Sastoji se od nekoliko jednostavnih primjera koje pomažu korisniku da se uhoda i što bezbolnije nauči koristiti programsko sučelje koje tehnologija pruža. \\
\hline
\end{tabular}
\end{table}

Osnovna programska apstrakcija s kojom tehnologija \emph{Apache Spark} radi je \emph{otporni raspodijeljeni skup podataka} (engl. \emph{resilient distributed dataset}, kratica RDD) \cite{workingSets}.
Atribut \emph{otproni} znači da se može ponovno rekonstruirati u slučaju da se particija uništi. \emph{Raspodijeljeni} znači da je to skup podataka koji se nalazi na računalima (jednom ili više njih) i moguće ga je paralelno obrađivati. \emph{Skup podataka} znači da predstavlja nekakvu kolekciju podataka. Tehnologija \emph{Apache Spark} nudi bogato programsko sučelje za rad s tim skupovima podataka.

\begin{figure}[htb]
\centering
\includegraphics[width=10cm]{img/gradivniElementiCropped.pdf}
\caption{Osnovni elementi tehnologije \emph{Apache Spark}.}
\label{fig:spark-stack}
\end{figure}
\pagebreak
Tehnologija se sastoji od nekoliko ključnih elemenata koji su u tablici \ref{tbl:gradivniElementi} samo nabrojani i opisani rečenicom ili dvije. Detaljnije objašnjenje nalazi se u kasnijim poglavljima. Slika \ref{fig:spark-stack} predstavlja osnovne elemente tehnologije \emph{Apache Spark}.

\begin{table}[htb]
\caption{Dio datoteka i direktorija dobivenih instalacijom.}
\label{tbl:gradivniElementi}
\centering
\begin{tabular}{l p{8cm}}
\hline
Komponenta & Opis \\
\hline
\emph{Spark SQL} & Omogućuje rad s bilo kakvim strukturiranim podatcima, primjerice \emph{JSON}. Također, nudi i mogućnost izvršavanja \emph{SQL} naredbi. \\
\emph{Spark Streaming} & Komponenta zadužena za rad s tokovima podataka. \\
\emph{MLib} & Koristi se za postupke strojnog učenja. \\
\emph{GraphX} & Biblioteka za obradu grafova (npr. graf prijatelja na društvenoj mreži).\\
\hline
\end{tabular}
\end{table}

\chapter{Prvi programi}
U ovom poglavlju opisano je kako napisati osnovni program koristeći tehnologiju \emph{Apache Spark}. Također je opisano i od čega se takav program sastoji i koja je uloga pojedine komponente programa. Primjer koji se obrađuje je primjer \ref{lst:brojanjeRijeci}, a svodi se na jednostavan algoritam brojanja riječi.

\section{Postavljanje temelja}
\subsection{Osnovni elementi aplikacije}
Općenito govoreći, svaka se Spark aplikacija sastoji  od nekoliko komponenata. Prva komponenta koju ćemo spomenuti je program koji se izvršava - onaj čija je \texttt{main} metoda pokrenuta, odnosno onaj koji pokreće obradu podataka. Taj program naziva se pozivajući program \engl{driver}. Pozivajući program s podatcima priča kroz "tunel" koji se naziva \emph{SparkContext}.

\begin{figure}[htb]
\centering
\includegraphics[scale=0.55]{img/elementiAplikacijeCropped.pdf}
\caption{Prikaz elemenata aplikacije.}
\label{fig:cluster-overview}
\end{figure}

Budući da je tehnologija \emph{Apache Spark} namijenjena za paralelnu obradu podataka, postoje još dvije komponente koje pridonose upravo tome. Pojedino računalo u \emph{grozdu} \engl{cluster} naziva se \emph{radnim čvorom} \engl{worker node}, a proces koji se izvršava na pojedinom računalu naziva se \emph{radnik} \engl{executor}. Dozvoljeno je da \emph{radnici} međusobno komuniciraju. U cijeloj priči može, a i ne mora eksplicitno biti uključen \emph{upravitelj grozdom} \engl{cluster manager}.
Opisana struktura prikazana je na slici \ref{fig:cluster-overview}.

\subsection{Korištenje tehnologije Apache Spark kroz programski jezik Java}
Kako bi mogli pisati Spark programe u programskom jeziku Java, potrebno je povezati svoju aplikaciju s \texttt{spark-core} artefaktom s Mavena. Za postavljanje i instalaciju Mavena konzultirati \url{https://maven.apache.org/install.html} i knjigu \cite{marcupic}. Za vrijeme pisanja ovog rada, najnovija verzija Sparka je 1.6.1, a odgovarajuće Maven koordinate su:
\begin{lstlisting}[language=bash, basicstyle=\small]
groupId = org.apache.spark
artifactId = spark-core_2.10
version = 1.6.1
\end{lstlisting}

Odgovarajuća \texttt{pom.xml} datoteka nalazi se u dodatku \ref{ch:datotekapomXML}.
Jednom kada je \texttt{pom.xml} datoteka namještena i projekt uspješno povezan sa \texttt{spark-core}, sve što je još potrebno jest inicijalizirati \emph{SparkContext} i napisati prvu aplikaciju. U primjeru \ref{lst:brojanjeRijeci} nalazi se jednostavna aplikacija koja jedino što radi je broji koliko puta se pojedina riječ pojavljuje u tekstualnoj datoteci.
\begin{lstlisting}[numbers=left, label={lst:brojanjeRijeci}, caption={Program koji broji koliko se puta koja riječ pojavljuje u datoteci.}]
package hr.fer.zemris;

import java.util.Arrays;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.*;
import org.apache.spark.api.java.function.*;

import scala.Tuple2;

/**
 * Razred ima svrhu prikazati osnovnu funkcionalnost Spark
 * tehnologije na primjeru prebrojavanja riječi
 * u tekstualnoj datoteci. Kao rezultat program će
 * zapisati u tekstualnu datoteku koja riječ se koliko puta
 * ponavlja. Očekuje se dva argumenta kroz naredbeni 
 * redak, a to su putanja do tekstualne datoteke u kojoj
 * treba izbrojati riječi i putanja do direktorija
 * u koji će se zapisati rezultat.
 *
 * @author mmatak
 *
 */
public class BrojanjeRijeci {
	/**
	 * Metoda koja se pokrene kada se pokrene program.
	 * Očekuje putanju do datoteke s riječima i putanju 
	 * do direktorija gdje će zapisati rezultat
	 * izvođenja programa.
	 *
	 * @param args
	 *            Argumenti naredbenog retka.
	 */
	@SuppressWarnings("serial")
	public static void main(String[] args) {
		if (args.length != 2) {
			System.out.println("Program očekuje 2 argumenta.");
		}
		String ulaznaDatoteka = args[0];
		String izlazniDirektorij = args[1];

		// inicijalizacija SparkContext-a
		SparkConf conf = new SparkConf().setMaster("local")
		.setAppName("Brojanje rijeci");
		JavaSparkContext sc = new JavaSparkContext(conf);

		// učitavanje podataka
		JavaRDD<String> ulaz = sc.textFile(ulaznaDatoteka);

		// razmak se koristi da bi razdvojio dvije riječi
		JavaRDD<String> rijeci = ulaz.flatMap(new FlatMapFunction<String, String>() {
			public Iterable<String> call(String redak) {
				return Arrays.asList(redak.split(" "));
			}
		});

		// transformiraj u parove (rijec,1) i broji
		JavaPairRDD<String, Integer> brojRijeci = rijeci
		.mapToPair(new PairFunction<String, String, Integer>() {
			public Tuple2<String, Integer> call(String rijec) {
				return new Tuple2<String, Integer>(rijec, 1);
			}
		}).reduceByKey(new Function2<Integer, Integer, Integer>() {
			public Integer call(Integer x, Integer y) {
				return x + y;
			}
		});

		// spremi rezultat u izlaznu datoteku
		brojRijeci.saveAsTextFile(izlazniDirektorij);
		// zatvori "tunel" odnosno SparkContext
		sc.close();
	}
}
\end{lstlisting}
\vspace{5mm}

Analizirajmo što smo napravili. Inicijalizirali smo \emph{SparkContext} tako što smo rekli da se odvija na lokalnom računalu i zadali smo ime aplikacije. Zatim smo kreirali RDD iz tekstualne datoteke koja je predana kao argument naredbenog retka. Taj skup podataka nam je poslužio za kreiranje novog skupa podataka koji je nastao tako što smo svaki redak razdvojili po razmaku i kreirali uređeni par (\emph{riječ}, 1). U tom uređenom paru, koji je oblika (\emph{ključ}, \emph{vrijednost}), \emph{riječ} nam predstavlja ključ, a 1 predstavlja vrijednost. Zatim smo iz tako uređenih parova, one parove koji imaju jednaki ključ zbrojili po vrijednostima i u tom trenutku\footnote{U tom trenutku se ništa dogodilo nego tek nakon poziva metode \texttt{saveAsTextFile()}, ali \emph{lijena evaluacija} \engl{lazy evaluation} opisana je tek kasnije.} nije više postojalo dva ili više uređena para koja imaju jednake ključeve. Na kraju smo rezultat zapisali i eksplicitno zatvorili \emph{SparkContext}. 

Kako je ovo bio početni primjer, \emph{lambda} izrazi koji su uobičajeni za programski jezik \emph{Java 8} nisu korišteni iz razloga da bi se lakše shvatilo što se sve treba implementirati. Odgovarajući kod koristeći lambda izraze dan je u primjeru \ref{lst:lambdaBrojanjeRijeci}.
\vspace{5mm}
\begin{lstlisting}[label={lst:lambdaBrojanjeRijeci}, caption={Brojanje riječi koristeći lambda izraze.}]
// razmak se koristi da bi razdvojio dvije riječi
JavaRDD<String> rijeci = ulaz.flatMap(redak -> Arrays.asList(" "));

// transformiraj u parove (rijec,1) i broji
		JavaPairRDD<String, Integer> brojRijeci = rijeci.mapToPair(
				 	rijec -> new Tuple2<String, Integer>(rijec, 1)
				 ).reduceByKey(
					 (x, y) -> x + y
				 );
\end{lstlisting}
\vspace{5mm}


\section{Otporni raspodijeljeni skup podataka}
\emph{Otporni raspodijeljeni skup podataka} (engl. \emph{resilient distributed dataset}, kratica RDD) je osnovna podatkovna struktura tehnologije Apache Spark. To je \emph{nepromjenjiva}, \emph{samo za čitanje} \engl{immutable, read-only} kolekcija podataka. Iz toga proizlazi da se iz jednog skupa podataka može jedino napraviti drugi skup podataka, a ne može se promijeniti postojeći. U prethodnom primjeru to je vidljivo pri pozivu metode \texttt{flatMap}. Ta metoda transformira \texttt{ulaz} u  \texttt{rijeci}. Sličnu transformaciju radi i metoda \texttt{mapToPair}. Drugim riječima, \emph{transformacija} \engl{transformation} je svaka metoda koja iz jednog skupa podataka kreira novi skup. Uz transformacije, postoje i \emph{akcije} \engl{actions}. Akcije se razlikuju od transformacija po tome što ne vraćaju novi skup podataka nego prvenstveno služe za dohvat jednog ili više elemenata iz nekog skupa. Dodatno, imaju mogućnost zapisivanja podataka kao što je prikazano u primjeru \ref{lst:brojanjeRijeci} - metoda \texttt{saveAsTextFile}.

U tablici \ref{tbl:transformacije} mogu se naći neke od mogućih transformacija i njihovi opisi, a u tablici \ref{tbl:akcije} nalaze se akcije koje je moguće pozvati zajedno s odgovarajućim opisima.
\begin{table}[htb]
\caption{Neke od transformacija nad otpornim raspodijeljenim skupovima podataka.}
\label{tbl:transformacije}
\centering
\begin{tabular}{lp{8cm}} 
\hline
Transformacija & Opis\\
\hline
\texttt{map(\emph{func})} & Vraća novi skup nastao tako što je svaki element orginalnog  skupa predan funkciji \emph{func}. \\
\texttt{filter(\emph{func})} & Vraća novi skup nastao tako što su iz orginalnog skupa preuzeti samo oni elementi za koje funkcija \emph{func} vraća \texttt{true}. \\
\texttt{flatMap(\emph{func})} & Slično kao \texttt{map(\emph{func})}, ali jedan ulazni element kreira 0 ili više izlaznih elemenata. \\
\texttt{union(\emph{drugiSkup})} & Vraća uniju između skupa nad kojim je transformacija pozvana i skupa koji je predan kao argument. \\
\texttt{intersection(\emph{drugiSkup})} & Vraća presjek između skupa nad kojim je transformacija pozvana i drugog skupa koji je predan kao argument. \\
\hline
\end{tabular}
\end{table}

Za detaljnije objašnjenje ovih i ostalih transformacija, pogledati \url{http://spark.apache.org/docs/latest/programming-guide.html#transformations}.
\\
\\
Budući da se radi o velikoj količini podataka, evaluacija transformacija je \emph{lijena} \engl{lazy evaluation}. To znači da Spark samo pamti koje sve transformacije treba napraviti nad skupovima, ali ne i da ih odmah odradi. Sve potrebne transformacije budu napravljene na zahtjev, odnosno tek pozivom prve akcije. 
\newpage
\begin{table}[htb]
\caption{Akcije primjenjive nad otpornim raspodijeljenim skupom podataka}
\label{tbl:akcije}
\centering
\begin{tabular}{lp{8cm}} 
\hline
Akcija & Opis \\
\hline
\texttt{reduce(\emph{func})} & Agregacija elemenata iz skupa tako što se nad dva elementa pozove funkcije \emph{func}, a ta funkcija vrati jedan element. Funkcija \emph{func} bi trebala biti komutativna i asocijativna kako bi se pravilno izvršavala u paralelnoj obradi podataka.\\
\texttt{collect()} & Vraća polje svih elemenata iz skupa direktno u pozivajući program. Budući da je tih elemenata puno, u praksi se poziva nakon transformacije \texttt{filter()}. \\
\texttt{count()} & Vraća broj elemenata u skupu. \\
\texttt{take(\emph{n})} & Vraća polje prvih \emph{n} elemenata iz skupa. \\
\texttt{first()} & Vraća prvi element iz skupa. Može se ostvariti i pozivom akcije \texttt{take(\emph{1})}\\
\hline
\end{tabular}
\end{table}
Za detaljnije objašnjenje ovih i ostalih akcija, pogledati \url{http://spark.apache.org/docs/latest/programming-guide.html#actions}.
\\

U nastavku slijedi primjer \ref{lst:primjer3} koji obrađuje datoteku \texttt{logfile.txt}.
Jedan od redaka te datoteke dan je u primjeru \ref{lst:redakDatoteke} i iz toga se može zaključiti kako općenito izgleda redak datoteke \texttt{logfile.txt}.
\begin{lstlisting}[label={lst:redakDatoteke}, basicstyle=\small, caption={Korištenje transformacija i akcija.}]
89.164.244.106 - [24/Feb/2008:01:05:08] "GET /index.jsp?lang=hr HTTP/1.1" 200
\end{lstlisting}

Primjer \ref{lst:primjer3} broji koliko puta je zahtjev bio na URL koji u sebi sadrži riječ "burza" i koliko je puta došao zahtjev na URL koji u sebi sadrži riječ "index". Njihova unija je također izračunata.
 
\vspace{5mm}
\begin{lstlisting}[label={lst:primjer3}, caption={Korištenje transformacija i akcija.}]
package hr.fer.zemris;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

public class Primjer3 {
	public static void main(String[] args) {
		// inicijalizacija SparkContext-a
		SparkConf conf = new SparkConf().setMaster("local")
				.setAppName("Brojanje rijeci");
		JavaSparkContext sc = new JavaSparkContext(conf);

		// učitavanje podataka
		JavaRDD<String> ulaz = sc.textFile("logfile.txt");

		// transformacije
		JavaRDD<String> burze = ulaz.filter(
				redak -> redak.contains("burza")
			);
		JavaRDD<String> indexi = ulaz.filter(
				redak -> redak.contains("index")
			);
		JavaRDD<String> unijaBI = burze.union(indexi);

		// akcije
		long brojLinija = unijaBI.count();
		long ukupanBrojLinija = ulaz.count();
		System.out.printf(
				"Broj linija koje sadrže riječ 'burza' ili 'index'
				 je: %d, odnosno %f%%.\n", brojLinija,
				 (double) 100 * brojLinija / ukupanBrojLinija
				 );
		System.out.printf(
				"Prva linija koja sadrži riječ 'burza' ili 'index'
				je: %s\n", unijaBI.first()
				);
		sc.close();
	}
}
\end{lstlisting}
\vspace{5mm}

Ovdje imamo 4 skupa podataka: \texttt{ulaz}, \texttt{burze}, \texttt{indexi} i \texttt{burzeUnijaIndexi}. Skupovi podataka \texttt{burze} i \texttt{indexi} su kreirani na temelju skupa podataka \texttt{ulaz}, a \texttt{unijaBI} je kreiran na temelju \texttt{burze} i na temelju \texttt{indexi}. Na slici \ref{fig:burzeUnijaIndexiRDD} nalazi se graf koji to opisuje.

\begin{figure}[htb]
\centering
\includegraphics[scale = 0.8]{img/transformacijeCropped.pdf}
\caption{Transformacije nad skupovima podataka.}
\label{fig:burzeUnijaIndexiRDD}
\end{figure}

Tek prilikom poziva akcije \texttt{burzaUnijaIndexi.count()} se zapravo kreira  \texttt{ulaz}, na temelju njega \texttt{burza} i \texttt{indexi} i onda tek na temelju njih se kreira \texttt{unijaBI}. Iz  \texttt{unijaBI} ukupni broj linija dohvati se pozivom \texttt{unijaBI.count()}. 
Nakon što se to izračuna, svi skupovi podataka nestaju iz memorije.  Prilikom poziva akcije \texttt{unijaBI.first()} \textbf{ponovno} se kreiraju prethodno navedeni skupovi podataka i sve ide iz početka.

Na prvi pogled ovo izgleda kao loša implementacija, ali budući da se ovdje radi o velikoj količini podataka i ne možemo ih nikako sve pohraniti u memoriju, ovo je zapravo logična implementacija. 
Ukoliko ne želimo svaki puta iz početka računati i kreirati \texttt{unijaBI}, trebamo ga pohraniti pozivom metode \texttt{persist()} i predavanjem odgovarajućeg parametra. Tablica \ref{tbl:razinePerzistencije} sadrži usporedbu različitih parametara koji se mogu predati metodi \texttt{persist()}.

\begin{table}[htb]
\scriptsize
\caption{Usporedba mogućih parametara za metodu \texttt{persist()}.}
\label{tbl:razinePerzistencije}
\centering
\begin{tabular}{lllll} 
\hline
Razina & Prostorno zauzeće & Procesorsko vrijeme & U memoriji & Na disku\\
\hline
\texttt{MEMORY\_ONLY} & Visoko & Nisko & Da & Ne  \\
\texttt{MEMORY\_ONLY\_SER} & Nisko & Visoko & Da & Ne  \\
\texttt{MEMORY\_AND\_DISK} & Visoko & Srednje & Dio & Dio \\
\texttt{MEMORY\_AND\_DISK\_SER} & Nisko & Visoko & Dio & Dio \\
\texttt{DISK\_ONLY} & Nisko & Visoko & Ne & Da \\
\hline
\end{tabular}
\end{table}

Iz tablice \ref{tbl:razinePerzistencije} očito je da postoje dvije osi usporedbe: spremanje na disk - spremanje u memoriju i spremanje u serijaliziranom obliku - spremanje u neserijaliziranom obliku. Postoji i parametar \texttt{MEMORY\_AND\_DISK} koji prvo podatke sprema u memoriju dok se memorija ne napuni, a kada se napuni, ostatak podataka se sprema na disk. Ono što razlikuje parametre koji sadrže postfiks \texttt{SER} i one koji ga ne sadrže je to što parametri s postfiksom \texttt{SER} spremaju podatke u serijaliziranom obliku, a drugi ne.


\chapter{Napredno programiranje}
U ovom poglavlju opisane su neke napredne tehnike za rad s tehnologijom \emph{Apache Spark}. Objašnjen je algoritam \emph{PageRank}, a dana je i implementacija istog u primjeru \ref{lst:pagerank}.
\section{Primjer: Algoritam PageRank}
Zanimljivo je pitanje kako je \emph{Google} toliko dobar u rezultatima koje korisnik dobije na svoj upit, točnije, kako ispravno sortira po relevantnosti stranice od važnije prema manje važnoj? Odgovor na to daje algoritam \emph{PageRank} koji je dobio ime po jednom od osnivača \emph{Googlea}, Larry Pageu. Ovo potpoglavlje analizira upravo algoritam \emph{PageRank}. U nastavku je iznesena pojednostavljena verzija algoritma, a više informacija o samom algoritmu nalazi se na \url{https://en.wikipedia.org/wiki/PageRank}. 

\subsection{Upoznavanje s algoritmom}
Algoritam računa koliko je koja stranica važna po tome koliko drugih stranica upućuje na nju. Ideja je jednostavna: što više stranica ima poveznicu na neku stranicu \texttt{N}, to je stranica \texttt{N} važnija i time bolje rangirana. U obzir se uzima i koja stranica pokazuje na stranicu \texttt{N} (je li to stranica na koju sve ostale stranice pokazuju ili je to neka stranica na koju nitko ne pokazuje) kao i na koliko ostalih stranica ta stranica sadrži poveznice (nije isto ako je na cijeloj stranici samo jedna poveznica i ako na cijeloj stranici ima 1000 poveznica). Stranice na koje neka stranica \texttt{M} sadrži poveznice nazivamo \emph{susjedima}.

Pojednostavljena izvedba algoritma je sljedeća:
\begin{enumerate}[label*=\arabic*.]
\item Početni rang svake stranice postavi se na $1.0$.
\item Ponavljaj \texttt{P} puta:
\begin{enumerate}[label*=\arabic*.]
\item Svaka stranica \texttt{\emph{n}} svim svojim susjedima šalje doprinos \texttt{rang(\emph{n})/brojSusjeda(\emph{n})}.
\item Postavi ukupni rang stranice prema formuli: $0.15 + 0.85*\emph{ukupan primljeni doprinos}$.
\end{enumerate}
\end{enumerate}

Kako bi se dobio što brže dobio što precizniji rezultat, važno je parametar \texttt{P} postaviti na \emph{ispravnu} vrijednost. U praksi je dovoljno \texttt{P} postaviti na 10. 

Pretpostavimo raspored stranica kao na slici \ref{fig:pageRankSusjedi}.

\begin{figure}[htb]
\centering
\includegraphics[scale = 0.5]{img/algoritamPageRankRucnoCropped.pdf}
\caption{Raspored susjeda u algoritmu}
\label{fig:pageRankSusjedi}
\end{figure}

U nastavku je raspisan algoritam \emph{PageRank} nad stranicama koje imaju susjede definirane kao na slici \ref{fig:pageRankSusjedi}. Ako stranica \texttt{N} sadrži poveznicu na stranicu \texttt{M} to je na toj istoj slici definirano tako da strelica počinje iz kruga s oznakom \texttt{N}, a vrh joj pokazuje na krug s oznakom \texttt{M}.

Intuitivno se čini da bi stranica \texttt{D} trebala biti najviše rangirana budući da najviše stranica upućuje na nju. Idemo to provjeriti. Za početak, odredimo susjede od svake stranice i postavimo rang svake stranice na $1.0$ kao što je prikazano u tablici \ref{tbl:pageRankKorak1}.
\pagebreak
\begin{table}[htb]
\caption{Inicijalizacija rangova i određivanje susjeda}
\label{tbl:pageRankKorak1}
\centering
\begin{tabular}{lll} 
\hline
Stranica & Rang & Susjedi \\
\hline
A & $1.0$ & B, E\\
B & $1.0$ & C\\
C & $1.0$ & D, F\\
D & $1.0$ & A\\
E & $1.0$ & G\\
F & $1.0$ & D\\
G & $1.0$ & D\\
\hline
\end{tabular}
\end{table}

Sada se ponavljaju koraci 2.1 i 2.2 \texttt{P} puta. Ovdje je ponovljeno 2 puta i to bi trebalo biti dovoljno za razumjevanje algoritma.
Iz koraka 2.1 računa se doprinos koja šalje svaka od stranica. Doprinos stranice \texttt{A} koji šalje drugima iznosi $1.0 / 2 = 0.5$. Doprinos stranice \texttt{B} koji šalje drugima je $1.0 / 2 = 0.5$. Doprinos stranice \texttt{C} jednak je kao i doprinos stranica \texttt{A} i \texttt{B} jer imaju jednak rang i broj susjeda. Doprinos stranica \texttt{D}, \texttt{E}, \texttt{F} i \texttt{G} iznosi $1.0 / 1 = 1.0$. Rezultati za svaku od stranica prikazani su u tablici \ref{tbl:pageRankKorak21p1}.

\begin{table}[htb]
\caption{Izračun doprinosa koji šalje svaka od stranica.}
\label{tbl:pageRankKorak21p1}
\centering
\begin{tabular}{llll} 
\hline
Stranica & Rang & Susjedi & Doprinos drugima\\
\hline
A & $1.0$ & B, E & 0.5\\
B & $1.0$ & C, D & 0.5\\
C & $1.0$ & D, F & 0.5\\
D & $1.0$ & A & 1.0\\
E & $1.0$ & G & 1.0\\
F & $1.0$ & D & 1.0\\
G & $1.0$ & D & 1.0\\
\hline
\end{tabular}
\end{table}

Sada, za svaku od stranica se računa ukupna suma koju je ta stranica dobila od svojih susjeda po formuli dana u koraku 2.2.
Budući da je stranica \texttt{A} susjed samo od stranice \texttt{D}, ukupni primljeni doprinos koji je primila stranica \texttt{A} je upravo doprinos koji stranica \texttt{D} može dati drugima, a to je $1.0$. Stranica \texttt{B} je susjed jedino stranici \texttt{A} i doprinos koji prima je upravo doprinos koji stranica \texttt{A} može u ovom trenutku dati drugima, a to je $0.5$. Stranica \texttt{C} je susjed jedino stranici \texttt{B} i zbog toga je njen ukupni primljeni doprinos $0.5$. Stranica \texttt{D} je susjed stranicama \texttt{B}, \texttt{C}, \texttt{F} i \texttt{G} pa je njen ukupni primljeni doprinos $0.5 + 0.5 + 1.0 + 1.0 = 3.0$. Ukupan primljeni doprinos za svaku od stranica nalazi se u tablici \ref{tbl:pageRankKorak22ap1}.
\pagebreak
\begin{table}[htb]
\caption{Ukupni primljeni doprinos svake od stranica.}
\label{tbl:pageRankKorak22ap1}
\centering
\begin{tabular}{lllll} 
\hline
Stranica & Rang & Susjedi & Doprinos drugima & Ukupni primljeni doprinos\\
\hline
A & $1.0$ & B, E & 0.5 & 1.0\\
B & $1.0$ & C, D & 0.5 & 0.5\\
C & $1.0$ & D, F & 0.5 & 0.5\\
D & $1.0$ & A & 1.0 & 3.0\\
E & $1.0$ & G & 1.0 & 0.5\\
F & $1.0$ & D & 1.0 & 0.5\\
G & $1.0$ & D & 1.0 & 1.0\\
\hline
\end{tabular}
\end{table}

Nakon što je izračunat ukupni primljeni doprinos, vrijeme je za ponovni izračun ranga svake od stanica po formuli koja se nalazi u koraku 2.2. Novi rang stranice \texttt{A} iznosi $0.15 + 0.85 * 1.0 = 1.0$. Novi rang stanice \texttt{B} iznosi $0.15 + 0.85 * 0.5 = 0.575$. Novi rang stranice \texttt{C} iznosi isto $0.575$ jer stranica \texttt{C} i stranica \texttt{B} imaju jednaki ukupni primljeni doprinos. Novi rang stranice \texttt{D} je $0.15 + 0.85 * 3.0 = 2.7$. Nakon što se izračuna i postavi novi rang za svaku od stranica, nastupi situacija kao u tablici \ref{tbl:pageRankStanje1}

\begin{table}[htb]
\caption{Rang svake od stranica nakon prve iteracije.}
\label{tbl:pageRankStanje1}
\centering
\begin{tabular}{lll} 
\hline
Stranica & Rang & Susjedi \\
\hline
A & $1.0$ & B, E\\
B & $0.575$ & C, D\\
C & $0.575$ & D, F\\
D & $2.7$ & A\\
E & $0.575$ & G\\
F & $0.575$ & D\\
G & $1.0$ & D\\
\hline
\end{tabular}
\end{table}

Vidimo da je već u prvoj iteraciji algoritma stranica \texttt{D} iskočila sa svojim rangom od okoline. Ovo smo bili i pretpostavili budući da je stranica \texttt{D} susjed najvećem broju stranica, odnosno najveći broj stranica sadrži poveznicu na stranicu \texttt{D}. 

Idemo napraviti još jednu iteraciju i vidjeti što će se dogoditi s rangovima. 

Iz tablice \ref{tbl:pageRankStanje1} dohvaćamo rang i broj susjeda svake od stranica te računamo doprinos koji svaka od stranica može dati svojim susjedima prema već spomenutoj formuli u gornjem algoritmu u koraku 2.1. Doprinos koji stranica \texttt{A} šalje drugima iznosi $1.0 / 2 = 0.5$. Doprinos koji stranica \texttt{B} šalje je $0.575 / 2 = 0.2875$. Doprinos stranice \texttt{C} je jednak doprinosu stranice \texttt{B} budući da imaju jednak rang i broj susjeda. Doprinos stranice \texttt{D} iznosi $2.7 / 1 = 2.7$. Doprinos stranica \texttt{E} i \texttt{F} iznosi $0.575$, a doprinos stranice \texttt{G} je $1.0$. Rezultati izračuna koliko koja stranica doprinosi drugima prikazani su u tablici \ref{tbl:pageRankKorak21p2}.

\begin{table}[htb]
\caption{Izračun doprinosa koji šalje svaka od stranica u drugoj iteraciji.}
\label{tbl:pageRankKorak21p2}
\centering
\begin{tabular}{llll} 
\hline
Stranica & Rang & Susjedi & Doprinos drugima\\
\hline
A & $1.0$ & B, E & 0.5\\
B & $0.575$ & C, D & 0.2875\\
C & $0.575$ & D, F & 0.2875\\
D & $2.7$ & A & 2.7\\
E & $0.575$ & G & 0.575\\
F & $0.575$ & D & 0.575\\
G & $1.0$ & D & 1.0\\
\hline
\end{tabular}
\end{table}

Sada se ponovno računa ukupni primljeni doprinos svake od stranica. Tako za stranicu \texttt{A} se dobije da ukupni primljeni doprinos iznosi $2.7$ jer je ona jedino susjed stranici D. Ukupni primljeni doprinos stranice \texttt{B} je $0.5$ jer je upravo to iznos koliko stranica \texttt{A} doprinosi drugima, a stranica \texttt{B} je jedino susjed od stranice \texttt{A}. Stranica \texttt{C} ima ukupni primljeni doprinos $0.2875$ jer je upravo to iznos doprinosa stranice \texttt{B}, a stranica \texttt{C} je susjed jedino stranici \texttt{B}. Stranica \texttt{D} prima zbroj doprinosa svih stranica kojima je susjed odnosno zbroj doprinosa stranica \texttt{B}, \texttt{C}, \texttt{F} i \texttt{G}. Iz toga proizlazi da je ukupni primljeni doprinos stranice \texttt{D} $0.2875 + 0.2875 + 0.575 + 1.0 = 2.15$. Ukupni primljeni doprinos za svaku od stranica nalazi se u tablici \ref{tbl:pageRankKorak22ap2} 

\begin{table}[htb]
\caption{Ukupni primljeni doprinos svake od stranica u drugoj tablici.}
\label{tbl:pageRankKorak22ap2}
\centering
\begin{tabular}{lllll} 
\hline
Stranica & Rang & Susjedi & Doprinos drugima & Ukupni primljeni doprinos\\
\hline
A & $1.0$ & B, E & 0.5 & 2.7\\
B & $0.575$ & C, D & 0.2875 & 0.5\\
C & $0.575$ & D, F & 0.2875 & 0.2875\\
D & $2.7$ & A & 2.7 & 2.15\\
E & $0.575$ & G & 0.575 & 0.5\\
F & $0.575$ & D & 0.575 & 0.2875\\
G & $1.0$ & D & 1.0 & 0.575\\
\hline
\end{tabular}
\end{table}

Nakon što je i u drugoj iteraciji izračunat ukupni primljeni doprinos, vrijeme je za ponovni izračun ranga svake od stanica po formuli koja se nalazi u koraku 2.2. Novi rang stranice \texttt{A} iznosi $0.15 + 0.85 * 2.7 = 2.445$. Novi rang stanice \texttt{B} iznosi $0.15 + 0.85 * 0.5 = 0.575$. Novi rang stranice \texttt{C} iznosi $0.15 + 0.85 * 0.2875 = 0.394375 $. Novi rang stranice \texttt{D} je $0.15 + 0.85 * 2.15 = 1.9775$.
Rang stranice \texttt{E} je $0.15 + 0.85 * 0.5 = 0.575$, a rang stranice \texttt{F} iznosi $0.15 + 0.85 * 0.2875 = 0.394375$. Konačno, rang stranice \texttt{G} je $0.15 + 0.85 * 0.575 = 0.63875$. Nakon što se postavi novi rang za svaku od stranica, nastupi situacija kao u tablici \ref{tbl:pageRankStanje2}

\begin{table}[htb]
\caption{Rang svake od stranica nakon prve iteracije.}
\label{tbl:pageRankStanje2}
\centering
\begin{tabular}{lll} 
\hline
Stranica & Rang & Susjedi \\
\hline
A & $2.445$ & B, E\\
B & $0.575$ & C, D\\
C & $0.394375$ & D, F\\
D & $1.9775$ & A\\
E & $0.575$ & G\\
F & $0.394375$ & D\\
G & $0.63875$ & D\\
\hline
\end{tabular}
\end{table}

Iz tablice \ref{tbl:pageRankStanje2} vidljivo je da je stranica \texttt{A} preuzela vodstvo. To se isto može intuitivno prihvatiti budući da skoro sve stranice pokazuju na stranicu \texttt{D}, a upravo \texttt{D} je jedina stranica koja pokazuje na \texttt{A}.

Nakon što se izvrti 10 iteracija, stvari se stabiliziraju. Graf koji opisuje kako se rangovi mijenjaju kroz 10 iteracija prikazan je slikom \ref{fig:grafRangIteracija}.

\begin{figure}[htb]
\centering
\includegraphics[scale = 0.5]{img/grafPageRankStraniceCropped.pdf}
\caption{Vrijednosti ranga ovisno o iteraciji}
\label{fig:grafRangIteracija}
\end{figure}

\subsection{Implementacija i analiza} \label{ssec:implAnalizaPRalg}
Kada je poznato kako "ručno" radi algoritam, ne bi trebao biti problem napisati programsku implementaciju koja se nalazi u primjeru \ref{lst:pagerank}. U ovom dijelu je osim samog koda napisana i detaljna analiza tog koda kako bi se dobilo što više informacija o tome kako radi tehnologija \emph{Apache Spark}. 

\vspace{5mm}
\begin{lstlisting}[numbers=left, label={lst:pagerank}, caption={Algoritam \emph{PageRank}.}, escapechar=|]
package hr.fer.zemris.naprednoProgramiranje;

import java.util.ArrayList;
import java.util.List;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

import com.google.common.collect.Iterables;

import scala.Tuple2;

/**
 * Program računa rang pojedine stranice. 
 * Očekuje se da svaki redak ulazne datoteke sadrži 
 * samo 2 stranice u formatu "StranicaA StranicaB", a taj
 * zapis predstavlja da je StranicaB susjed od StranicaA.
 * 
 * @author mmatak
 *
 */
public class AlgoritamPageRank {
	private static final String ULAZNA_DATOTEKA = "pageRankInput.txt";
	private static final int BROJ_ITERACIJA = 10;

	public static void main(String[] args) {
		// Inicijalizacija SparkContext-a.
		SparkConf conf = new SparkConf().setMaster("local") |\label{line:initStart}|
				.setAppName("Algoritam PageRank");
		JavaSparkContext sc = new JavaSparkContext(conf); |\label{line:initEnd}|

		// Učitavanje podataka.
		JavaRDD<String> ulaz = sc.textFile(ULAZNA_DATOTEKA); |\label{line:ucitavanje}|

		// Pročitaj sve ulazne URL-e i inicijaliziraj njihove susjede.
		JavaPairRDD<String, Iterable<String>> linkovi = ulaz.mapToPair(|\label{line:susjediInitStart}|
				redak -> {
					String[] elementi = redak.split("\\s+");
					return new Tuple2<String, String>(elementi[0], elementi[1]);
				}).distinct().groupByKey().cache(); |\label{line:susjediInitEnd}|
		// Svako ime susjeda zamijeni s 1.0 i vrati novi skup podataka.
		JavaPairRDD<String, Double> rangovi = linkovi.mapValues(value -> 1.0); |\label{line:initRangovi}|

		// iteracija 2. i 3. koraka algoritma
		for (int i = 0; i < BROJ_ITERACIJA; i++) { |\label{line:brIteracijaStart}|
			// za svaki link izracunaj njegovu doprinos drugim linkovima
			JavaPairRDD<String, Double> doprinosi =
			linkovi.join(rangovi).values().flatMapToPair(|\label{line:joinValues}|
				linkoviRang -> { 	|\label{line:linkoviRangPocetak}|
			
					int brojSusjeda = Iterables.size(linkoviRang._1); |\label{line:brojSusjeda}|
					List<Tuple2<String, Double>> rezultati = new ArrayList<Tuple2<String, Double>>();
					
						for (String susjed : linkoviRang._1) { |\label{line:petljaStart}|
							rezultati.add(new Tuple2<String, Double>(
							susjed, linkoviRang._2 / brojSusjeda));
						} |\label{line:petljaKraj}|
						
						return rezultati; |\label{line:linkoviRangKraj}|					
				}
			);
			rangovi = doprinosi.reduceByKey((v1, v2) -> v1 + v2) |\label{line:zbrojPoKljucu}|
					.mapValues(suma -> 0.15 + suma * 0.85); |\label{line:postaviRang}|
		} |\label{line:brIteracijaKraj}|
		// spremi u memoriju
		List<Tuple2<String, Double>> rangoviFinal = rangovi.collect(); |\label{line:spremanjePodataka}|
		// ispis
		for (Tuple2<String, Double> entry : rangoviFinal) {
			System.out.printf("Stranica %s ima rang %.2f\n", entry._1, entry._2);
		}
		sc.close();
	}
}
\end{lstlisting}
\vspace{5mm}

Analizirajmo kod naveden u primjeru \ref{lst:pagerank}. 

Od linije \ref{line:initStart} do linije \ref{line:initEnd} inicijalizira se glavno računalo i ime aplikacije. Ovdje je glavno računalo postavljeno na \texttt{local} budući da se aplikacija odvija na lokalnom računalu, a ne na grozdu. Ime aplikacije postavljeno je na temelju algoritma kojeg aplikacija implementira.

Linija \ref{line:ucitavanje} obavlja inicijalizaciju \emph{otpornog raspodijeljenog skupa podataka} čitajući podatke iz datoteke čija je putanja zadana varijablom \texttt{ULAZNA\_DATOTEKA}.

Od linije \ref{line:susjediInitStart} do linije \ref{line:susjediInitEnd} obavlja se pridruživanje susjeda svakoj stranici. Svaki se redak iz skupa \texttt{ulaz} podijeli na dva elementa - element prije i element poslije razmaka. Ta dva elementa predstavljaju uređeni par (\emph{ključ}, \emph{vrijednost}) gdje je stranica koja je prije razmaka \emph{ključ}, a stranica nakon razmaka \emph{vrijednost}. To znači da je stranica \emph{vrijednost} susjed od stranice \emph{ključ}. Budući da su dozvoljeni duplikati u ulaznom skupu podataka tj. može postojati dva identična retka koja govore kako stranica \emph{N} ima susjeda \emph{M}, to se mora uzeti u obzir. Za rangiranje stranice nije bitno koliko poveznica stranica \emph{N} sadrži na stranicu \emph{M}. U ovoj implementaciji, svejedno je radi li se o 1 ili 1000 poveznica jer su to sve iste poveznice. Da bi se osiguralo da ne postoji niti jedan duplikat, poziva se metoda \texttt{distinct()}. Pozivom metode \texttt{groupByKey()} obavlja se \emph{spajanje} uređenih parova s istim ključem, a njihove vrijednosti spremamo u listu. Primjerice, postoje li kolekcija uređenih parova (\emph{A}, \emph{B}), (\emph{A}, \emph{C}), (\emph{A}, \emph{D}) i nad tom kolekcijom pozove se \texttt{groupByKey()} rezultat će biti uređeni par (\emph{A}, \{\emph{B}, \emph{C}, \emph{D}\}). \emph{Vrijednost} tog uređenog para je iterabilna (implementira sučelje \texttt{Iterable}) i zbog toga je povratna vrijednost u obliku \texttt{JavaPairRDD<String, Iterable<String>{}>}. Rezultat je skup podataka \texttt{linkovi} predstavljen uređenim parovima gdje su \emph{ključevi} stranice, a \emph{vrijednosti} susjedi tih stranica. Konačno, kako se ne bi ovo moralo svaki puta ispočetka računati, rezultat se pohranjuje u memoriju pozivom metode \texttt{cache()}.

Linija \ref{line:initRangovi} iz skupa podataka \texttt{linkovi} "provuče" svaku od \emph{vrijednosti} (čitava kolekcija je zapravo jedna \emph{vrijednost}) kroz funkciju koja tu čitavu kolekciju samo preslika u \emph{vrijednost} $1.0$. Sada je nastao novi skup uređenih parova koji za \emph{ključ} imaju stranicu, a za \emph{vrijednost} $1.0$. Ovim postupkom je zapravo postavljen rang svake stranice na početnu vrijednost.

Poziv naredbe \texttt{linkovi.join(rangovi)} u liniji \ref{line:joinValues} vraća novi skup podataka koji kao \emph{ključeve} ima \emph{ključeve} iz skupova \texttt{linkovi} i \texttt{rangovi} (bez dupliciranja), a odgovarajuće \emph{vrijednosti} su uređeni parovi \emph{vrijednosti} iz tih skupova. Preciznije rečeno, \texttt{join(\emph{drugiSkupPodataka})} ako je pozvan nad skupovima uređenih parova oblika (\emph{K},\emph{V}) i (\emph{K}, \emph{W}) kao rezultat vraća skup podataka uređenih parova oblika (\emph{K},(\emph{V}, \emph{W})). Ukoliko postoje različiti \emph{ključevi} u skupovima podataka nad kojima se izvršava \texttt{join()}, parovi s stim \emph{ključem} su ignorirani. Jedino se "uparuju" uređeni parovi s istim \emph{ključem}. Metoda \texttt{values()} vraća skup svih \emph{vrijednosti} iz skupa podataka dobivenog pozivom metode \texttt{join()}. U ovom primjeru metoda \texttt{values()} vraća skup uređenih parova gdje je \emph{ključ} kolekcija susjeda neke stranice, a \emph{vrijednost} rang te stranice. Metoda \texttt{flatMapToPair()} kao argument prima funkciju koja implementira sučelje \texttt{PairFlatMapFunction<T,K2,V2>}. Ta funkcija prima element tipa \texttt{T} i vraća nula ili više uređenih parova oblika (\texttt{K2}, \texttt{V2}). Metoda \texttt{flatMapToPair()} zapravo "provuče" svaki element skupa nad kojim je pozvana kroz funkciju koju primi kao argument i na kraju, na temelju uređenih parova koje je ta funkcija vratila, kreira skup podataka oblika (\texttt{K2}, \texttt{V2}). Element koji se "provlači" imenovan je varijablom \texttt{linkoviRang}.

Od linije \ref{line:linkoviRangPocetak} do linije \ref{line:linkoviRangKraj} obrađuju se podatci koji su predstavljeni uređenim parovima oblika (\emph{ključ}, \emph{vrijednost}) gdje je \emph{ključ} kolekcija susjeda neke stranice, a \emph{vrijednost} rang te stranice.

Linija \ref{line:brojSusjeda} zapravo dohvaća veličinu kolekcije koja je predstavljena \emph{ključem}, odnosno varijablu \texttt{brojSusjeda} postavlja na onu vrijednost koliko stranica koja se trenutno obrađuje ima susjeda. 

Od linije \ref{line:petljaStart} do linije \ref{line:petljaKraj} proteže se petlja koja u listu \texttt{rezultati} sprema uređene parove oblika (\emph{ključ}, \emph{vrijednost}) gdje je \emph{ključ} susjed, a \emph{vrijednost} doprinos stranice koja se trenutno obrađuje tom susjedu. 

Funkcija \texttt{flatMapToPair()} spaja sve vraćene rezultate u jedan skup i  sada se u skupu podataka \texttt{doprinosi} nalaze uređeni parovi gdje je \emph{ključ} stranica, a \emph{vrijednost} doprinos neke stranice toj stranici. Budući da neka stranica ne mora biti susjed samo jednoj stranici, u tom skupu podataka se može naći više parova s istim ključem - svaka vrijednost je doprinos od neke druge stranice. 

Linija \ref{line:zbrojPoKljucu} "spaja" sve parove s istim \emph{ključem} tako što od više uređenih parova s istim \emph{ključem} stvori jedan uređeni par s tim \emph{ključem}, a \emph{vrijednosti} zbroji. Time je zapravo izračunat ukupni primljeni doprinos svake od stranica i nastao je novi skup uređenih parova oblika (\emph{stranica}, \emph{ukupni primljeni doprinos}). 

Linija \ref{line:postaviRang} dohvaća \emph{vrijednosti} iz tih uređenih parova i na temelju njih računa nove \emph{vrijednosti} i postavlja ih kao trenutne \emph{vrijednosti}. Nove \emph{vrijednosti} su zapravo novi rangovi svake od stranica. Sada se u varijabi \texttt{rangovi} nalaze uređeni parovi (\emph{stranica}, \emph{rang}) . 

Postupak od linije \ref{line:brIteracijaStart} do linije \ref{line:brIteracijaKraj} ponavljamo potrebni broj puta kako bi se rang svake od stanica postavio na što ispravniju vrijednost. Kao što je već rečeno, u praksi je to desetak puta pa je tako i u ovom primjeru.

Kada su izračunati rangovi svake od stanica, sve što još treba je ispisati podatke. Kako bi se uštedilo na vremenu (ponovno računanje rangova svaki puta kada treba raditi nešto s tim rangovima), dohvaćamo sve podatke iz skupa podataka \texttt{rezultati} i spremamo ih u varijablu \texttt{rezultatiFinal}. Taj dio je prikazan linijom \ref{line:spremanjePodataka}.

Konačno, u \texttt{for} petlji iteriramo po elementima liste \texttt{rezultatiFinal} te ispišemo ime i rang stranice. Na kraju zatvorimo \emph{SparkContext}.


\section{Skupovi podataka kao uređeni parovi}
U primjeru \ref{lst:pagerank} već je uveden pojam skupa podataka koji je predstavljen uređenim parom (\emph{ključ}, \emph{vrijednost}). U ovoj tehnologiji takav skup podataka nije rijetkost i zbog toga postoji niz transformacija nad upravo tim oblikom skupa podataka, a neke od njih su već objašnjene u potpoglavlju \ref{ssec:implAnalizaPRalg}. Osnovne informacije mogu se pronaći u tablicama \ref{tbl:transformacijeJedanPairRDD} i \ref{tbl:transformacijeDvaPairRDD}, a za više informacija, konzultirati službenu dokumentaciju \url{http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaPairRDD.html}.

\begin{table}[htb]
\caption{Neke od transformacija nad jednim skupom podataka koji predstavljen uređenim parovima. Primjer: \{(1, 2), (3, 4), (3, 6)\}.}
\label{tbl:transformacijeJedanPairRDD}
\centering
\begin{tabular}{lp{3cm}p{4cm}p{1.5cm}} 
\hline
Transformacija & Opis & Primjer korištenja & Rezultat\\
\hline

\texttt{reduceByKey(\emph{func})} & Kombinira vrijednosti s istim \emph{ključem}. & rdd.reduceByKey((x,y) -> x + y) & \{(1, 2), (3, 10)\}\\

\texttt{groupByKey()} & Grupira vrijednosti s istim \emph{ključem}. & rdd.groupByKey() & \{(1, [2]), (3, [4, 6])\}\\

\texttt{mapValues(\emph{func})} & Primjena funkcije nad svakom \emph{vrijednosti} u uređenom paru, \emph{ključ} ostaje nepromijenjen. & rdd.mapValues(\newline x -> x + 10) & \{(1, 12), (3, 14), (3, 16)\}\\


\texttt{keys()} & Vraća novi skup podataka koji se sastoji od svih \emph{ključeva}. & rdd.keys() & \{1, 3, 3\}\\


\texttt{values()} & Vraća novi skup podataka koji se sastoji od svih \emph{vrijednosti}. & rdd.values() & \{2, 4, 6\}\\
\hline
\end{tabular}
\end{table}

Često postoji potreba za transformacijom koja je kombinacija dva skupa podataka. Primjerice, spajanje tablica iz baze podataka. Te stvari su moguće i ovdje, a samo neke od transformacija prikazane su u tablici \ref{tbl:transformacijeDvaPairRDD}. Osim transformacija, postoje i akcije koje je moguće izvoditi nad otpornim raspodijeljenim skupom podataka koji je predstavljen kao uređeni par, ali radi formata ovog rada, nije napisana još jedna tablica gdje bi te akcije bile objašnjene. Za informacije o akcijama, konzultirati \cite{officialDocumentation}.

\begin{table}[htb]
\caption{Neke od transformacija nad dva skupa podataka koji su predstavljeni uređenim parovima. Primjer: rdd = {(1, 2), (3, 4), (3, 6)}, drugi = {(3,9)}.}
\label{tbl:transformacijeDvaPairRDD}
\centering
\begin{tabular}{lp{3cm}p{4cm}p{1.5cm}} 
\hline
Transformacija & Opis & Primjer korištenja & Rezultat\\
\hline

\texttt{subtractByKey} & Briše parove koji imaju iste \emph{ključeve}. & rdd.subtractByKey(drugi) & \{(1, 2)\}\\

\texttt{join} & Obavlja operaciju \emph{prirodnog spajanja} \engl{inner join} & rdd.join(drugi) & \{(3, (4, 9)), (3, (6, 9))\}\\
\hline
\end{tabular}
\end{table}

Ono što je još često potrebno, a nije već spomenuto jest sortiranje podataka. Tehnologija \emph{Apache Spark} omogućuje i sortiranje uređenih parova po \emph{ključu}. Transformacija se naziva \texttt{sortByKey} i primjer poziva je \texttt{rdd.sortByKey()}. Prima argument treba li sortirati uzlazno (podrazumijevana vrijednost) ili silazno. Dodatno, moguće je i predati komparator koji će usporediti ključeve. 

\section{Čitanje i spremanje podataka }
U ranijim primjerima prikazano je kako ostvariti čitanje podataka iz tekstualne datoteke kao i kako zapisati rezultat u neku tekstualnu datoteku. Neki od podržanih oblika tekstualnih datoteka su JSON, CSV i TSV oblik. Tehnologija \emph{Apache Spark} omogućuje i puno više. Između ostalog, moguće je čitati i pisati direktno u bazu podataka (Cassandra, HBase, Elasticsearch, JDBC), strukturirane izvore uključujući JSON i Apache Hive, a isto tako moguće je čitati i podatke koji su spremljeni na raspodijeljenom sustavu datoteka poput NFS, HDFS ili Amazon S3.

Datoteke u JSON obliku se učitaju poput tekstualne datoteke, a zatim se parsira JSON format. Za parsiranje JSON formata se u pravilu koriste gotove biblioteke, a popularna biblioteka za Javu naziva se \emph{Jackson}. Više informacija o tim bibliotekama može se pronaći na \url{http://geokoder.com/java-json-libraries-comparison}. 

Više informacija o čitanju i spremanju podataka potražiti u poglavlju \emph{Loading and saving your data}\cite{learningSpark}.

\section{Dijeljene varijable}
Funkcija koju predamo metodi \texttt{map()} vidi varijable koje su definirane u \emph{pozivajućem programu}, ali svaki \emph{zadatak} \engl{task} koji se vrti na \emph{grozdu} dobije svoju kopiju vrijednosti tih varijabli, a nove vrijednosti tih varijabli nisu propagirane \emph{pozivajućem programu}. Riješenje ovog problema su dijeljene varijable \engl{shared variables}. Ime su dobile po tome što je njihova \emph{ispravna} vrijednost vidljiva svuda u grozdu.

\subsection{Odašiljatelji}
Ukoliko je potrebno dohvaćati vrijednost neke varijable na cijelom grozdu, potrebna je \emph{varijabla odašiljatelj} \engl{broadcast variable}. Ta varijabla se pohranjuje u memoriji i zbog toga ne smije zauzimati puno prostora. Također, takva varijabla je nepromjenjiva \engl{immutable}. Moguće je slati i promjenjivu varijablu, ali ta promjena će biti jedino vidljiva na tom čvoru koji je promjenu napravio, a takvo ponašanje u pravilu nije poželjno. 

Kao što je navedeno u \cite{officialDocumentation}, \emph{odašiljatelji} se mogu koristiti kao statičke lookup tablice \engl{lookup table}. 
Pretpostavimo da radimo na aplikaciji koja u bazi ima dvije tablice, tablicu koja pamti identifikator i ime naselja te tablicu koja pamti identifikator korisnika koji se prijavio i identifikator naselja gdje se prijavio. Primjer takvih tablica su tablice \ref{tbl:naselja} i \ref{tbl:prijave}.

\begin{table}[htb]
\caption{Tablica \texttt{naselja}.}
\label{tbl:naselja}
\centering
\begin{tabular}{ll} 
\hline
\texttt{id} & \texttt{ime}\\
\hline
1 & Centar\\
2 & Maksimir\\
3 & Jordanovac\\
4 & Siget\\
5 & Dubrava\\
\hline
\end{tabular}
\end{table}

Zadatak je saznati ime naselje za svaku od prijava. Pretpostavka je da postoji jako puno prijava, a ne previše naselja tj. prijave su u nekoj velikoj tablici, a naselja su u maloj tablici. Pri obavljanju klasične transformacije \texttt{join}, podatci obje tablice bi putovali svuda po mreži i to bi uzelo puno vremena i mrežnih resursa. Ukoliko je potrebno napraviti \texttt{join} male i velike tablice, bolje rješenje je malu tablicu (koja stane u memoriju i ne mijenja se) postaviti kao varijablu \emph{odašiljatelj}. Na taj način, jedino će mala tablica putovati preko mreže. U ovom primjeru, mala tablica je tablica \texttt{naselja} \ref{tbl:naselja}, a velika tablica je tablica \texttt{prijave} \ref{tbl:prijave}. 

Varijable koje su postavljene kao \emph{odašiljatelj} preko mreže se prenose bittorent protokolom. To znači da što više čvorova treba tu varijablu, ta varijabla se brže širi po mreži\footnote{Više informacija o bittorent protokolu na stranici \url{http://www.bittorrent.org/}}. 

\vspace{5mm}
\begin{lstlisting}[numbers=left, label={lst:odasiljateljPrimjer}, caption={Korištenje odašiljatelja.}, escapechar=|]
package hr.fer.zemris.naprednoProgramiranje;

import java.util.Map;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.broadcast.Broadcast;

import scala.Tuple2;

public class Primjer5 {
	public static void main(String[] args) {
		// Inicijalizacija SparkContext-a.
		SparkConf conf = new SparkConf().setMaster("local")
				.setAppName("Razasiljane varijable");
				
		try (JavaSparkContext sc = new JavaSparkContext(conf)) {
		
			// inicijalizacija naselja
			JavaPairRDD<String, String> naseljaRDD = sc
				.textFile("tblNaselja.txt").mapToPair(
					redakTablice -> {
						String[] redak = redakTablice.split(",");
						return new Tuple2<String, String>(redak[0], redak[1]);
					});
					
			// prijave
			JavaPairRDD<String, String> prijaveRDD = sc
					.textFile("tblPrijave.txt").mapToPair(redakTablice -> {
						String[] redak = redakTablice.split(",");
						return new Tuple2<String, String>(redak[0], redak[1]);
					});
							
			// odasiljanje read only varijable "naselja" kroz grozd
			final Broadcast<Map<String, String>> naselja = sc
					.broadcast(naseljaRDD.collectAsMap());

			
			JavaPairRDD<String, Tuple2<String, String>> imenovanePrijave = prijaveRDD
					.mapToPair(
						prijava -> new Tuple2<String, Tuple2<String, String>>(
								prijava._1,
								new Tuple2<String, String>(
									prijava._2,
									naselja.getValue().get(prijava._2)
								)
							)
						);
			//ispis
			for (Tuple2<String, Tuple2<String, String>> element : imenovanePrijave
					.collect()) {
				System.out.printf("Id prijave: %s \t Ime naselja: %s\n",
						element._1, element._2._2);
			}
		}
	}
}
\end{lstlisting}
\vspace{5mm}

U primjeru \ref{lst:odasiljateljPrimjer} pokazano je korištenje odašiljatelja. Osim toga, u tom primjeru je \emph{SparkContext} inicijaliziran u \emph{try-catch} bloku naredbi. Budući da \emph{SparkContext} implementira sučelje \texttt{Closeable}, to je garancija da ako ga otvorimo \emph{try-catch} inicijalizacijskom bloku da će biti i pravovremeno zatvoren.

Program čita iz datoteke \texttt{tblNaselja.txt} podatke o naseljima koji su zapisani u obliku \emph{id\_naselja,ime\_naselja}. Podatci o prijavama imaju oblik \emph{id\_prijave,id\_naselja} i čitaju se iz datoteke \texttt{tblPrijave.txt}. Podatci u tim datotekama jednaki su podatcima iz tablica \ref{tbl:naselja} i \ref{tbl:prijave}. Nakon što su podatci učitani, kreirani su skupovi podataka. Zatim se skup podataka koji predstavlja tablicu \ref{tbl:naselja} pretvorio u mapu gdje je \emph{ključ} identifikator naselja, a \emph{vrijednost} ime naselja. Takva mapa je \emph{odaslana} svuda po mreži. 

\begin{table}[htb]
\caption{Tablica \texttt{prijave}.}
\label{tbl:prijave}
\centering
\begin{tabular}{ll} 
\hline
\texttt{id\_korisnik} & \texttt{id\_naselje}\\
\hline
112312 & 1\\
243242 & 2\\
254331 & 2\\
432115 & 1\\
567893 & 4\\
537893 & 4\\
\hline
\end{tabular}
\end{table}

Nakon toga, za svaku prijavu, kreiran je novi uređeni par koji za \emph{ključ} ima identifikator prijave, a za vrijednost objekt \texttt{Tuple2} koji za prvu vrijednost ima identifikator nasilja, a za drugu vrijednost ime tog naselja. Razred \texttt{Tuple2} preuzet je iz programskog jezika Scala i predstavlja uređeni par (\emph{vrijednost\_1}, \emph{vrijednost\_2}). Shodno tome, prvoj vrijednosti se pristupa preko \texttt{element.\_1}, a drugoj vrijednost preko \texttt{element.\_2}.

Na kraju su ispisani svi dobiveni podatci, a rezultat je prikazan u primjeru \ref{lst:rezultati}.
\begin{lstlisting}[label={lst:rezultati}, caption={Identifikatori prijave i imena naselja odakle su prijave poslane.}]
Id prijave: 112312 	 Ime naselja: Centar
Id prijave: 243242 	 Ime naselja: Maksimir
Id prijave: 254331 	 Ime naselja: Maksimir
Id prijave: 432115 	 Ime naselja: Centar
Id prijave: 567893 	 Ime naselja: Siget
Id prijave: 537893 	 Ime naselja: Siget
\end{lstlisting}

\subsection{Akumulatori}
Ako se odašiljatelje gleda kao globalne \emph{gettere}, \emph(akumulatore) \engl{accumulators} se može gledati kao na globalne \emph{settere}. Za razliku od odašiljatelja koji svim čvorovima dojavljuju vrijednost, akumulatori akumuliraju, odnosno dohvaćaju vrijednost svakog čvora. Ideja je jednostavna, ako je potrebno s iz više radnih čvorova mijenjati nekakvu globalnu varijablu, ta varijabla se postavi kao akumulator.

U datoteci \texttt{log.txt} pohranjeni su zapisi pristupanju na server. Svaki zapis je u novom retku. Ukoliko u nekom retku postoji riječ \texttt{error}, taj zapis nije valjan. Svaki drugi zapis je valjan. Zadatak je izbrojati koliko postoji valjanih zapisa i koliko postoji zapisa koji nisu valjani. Jedno od riješenja je koristiti dva akumulatora: jedan za valjane zapise i drugi za zapise koji nisu valjani. Programska implementacija tog rješenja dana je u primjeru \ref{lst:akumulatoriPrimjer}.

\begin{lstlisting}[numbers=left, label={lst:akumulatoriPrimjer}, caption={Korištenje akumulatora.}, escapechar=|]
package hr.fer.zemris.naprednoProgramiranje;

import org.apache.spark.Accumulator;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

public class Primjer6 {
	public static void main(String[] args) {
		SparkConf conf = new SparkConf().setMaster("local")
				.setAppName("Koristenje akumulatora");
		try (JavaSparkContext sc = new JavaSparkContext(conf)) {
			// inicijalizacija naselja
			JavaRDD<String> zapisi = sc.textFile("log.txt");

			// inicijalizacija akumulatora
			Accumulator<Integer> valjaniZapisi = sc.accumulator(0);
			Accumulator<Integer> neValjaniZapisi = sc.accumulator(0);

			// obrada podataka
			for (String redak : zapisi.collect()) {
				if (redak.contains("error")) {
					neValjaniZapisi.add(1);
				} else {
					valjaniZapisi.add(1);
				}
			}
			// ispis rezultata
			System.out.printf("Valjanih zapisa ima %d\n",
					valjaniZapisi.value());
			System.out.printf("Nevaljanih zapisa ima %d\n",
					neValjaniZapisi.value());
		}
	}
}

\end{lstlisting}

\chapter{Zaključak} 
Zaključak.


\begin{thebibliography}{9}
\bibitem{officialDocumentation}
  Službena dokumentacija projekta \emph{Apache Spark} \url{http://spark.apache.org/docs/latest/} , posjećeno 1.5.2016
\bibitem{learningSpark}
  Holden Karau, Andy Konwinski, Patrick Wendell i Matei Zaharia
  \emph{Learning Spark, lighting-fast}, O'Reilly 2015.
\bibitem{marcupic}
  Marko Čupić,
  \emph{Programiranje u Javi},
  verzija 0.3.26
\bibitem{workingSets}
  Matei Zaharia, Mosharaf Chowdhury, Michael J. Franklin, Scott Shenker, Ion Stoica,
  \emph{Spark: Cluster Computing with Working Sets}, University of California, Berkeley
\end{thebibliography}

\newpage
% Dodatak nije obavezan
\begin{appendices}
\chapter{Instalacija}
\label{ch:instalacijaSpark}
Ovdje će biti prikazana instalacija na operacijskom sustavu \emph{Ubuntu 15.10}. Ovo nije veliko ograničenje jer se iz ovih uputa može zaključiti i kako instalacija ide za neki drugi operacijski sustav.

Za početak je potrebno imati instaliranu Javu, a je li Java instalirana na računalu se može provjeriti tako što se u naredbenom retku unese sljedeća naredba:\\
\texttt{java -version}. Kao rezultat bi trebali dobiti trenutno instaliranu verziju Jave. Ukoliko Java nije instalirana, potrebno ju je najprije instalirati. Više informacija o instalaciji se može pronaći u \cite{marcupic}.

Jednom kada imamo instaliranu Javu, sve što treba napraviti je otići na službene stranice: \url{https://spark.apache.org/downloads.html}, odabrati najnoviju verziju (Za vrijeme pisanja ovog rada to je verzija \emph{1.6.1 (Mar 09 2016}), izabrati odgovarajući paket te pokrenuti dohvaćanje odgovarajuće \emph{.tgz} arhive. Najjednostavnije je odabrati neki \emph{pre-built} paket, primjerice \emph{Pre-built for Hadoop 2.6 and later}. Daljnji koraci instalacije su napisani pod pretpostavkom da je dohvaćena ta verzija paketa. Moguće je instalirati i \emph{Source code} varijantu paketa, ali taj postupak instalacije ovdje nije opisan. 

Nakon što je dohvaćena odgovarajuća arhivu, potrebno ju je raspakirati.\\ Raspakiranje arhive moguće je napraviti preko naredbe:
\begin{lstlisting}[language=bash]
$ tar -xvf spark-1.6.1-bin-hadoop2.6.tgz
\end{lstlisting}
Nakon toga, dobra je praksa premjestiti instalaciju u neki prikladniji direktorij. Tako nešto može se napraviti na sljedeći način:
\begin{lstlisting}[language=bash]
$ mv Downloads/spark-1.6.1-bin-hadoop2.6 faks/spark/
\end{lstlisting}
Ovim korakom je instalacija završena. 

Kako bi bili sigurni da je instalacija uspješna, potrebno je pozicionirati se u \emph{bin} direktorij te u terminalu upisati \texttt{./spark-shell}. Ispis bi trebao biti sličan ovome:\\
\begin{lstlisting}[language=bash]
mmatak@martins-beast:~/faks/spark/bin$ ./spark-shell
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.6.1
      /_/

Using Scala version 2.10.5 (OpenJDK 64-Bit Server VM, Java 1.8.0_91)
Type in expressions to have them evaluated.
Type :help for more information.
scala>
\end{lstlisting}


Ukoliko se prikaže greška vezana uz \emph{sqlContext}, to nije razlog za brigu. U ovom trenutku to nije važno. Radi ljepšeg formata ovog rada, u gornjem ispisu izbrisana su upozorenja \engl{warnings}.
\chapter{Postavljanje datoteke pom.xml}
\label{ch:datotekapomXML}
Datoteka koja je potrebna kako bi Maven ispravno dohvatio artifakt \texttt{spark-core} bi trebala izgledati slično kao što je dano u nastavku. Za ispravno funkcioniranje, trebala bi se zvati \texttt{pom.xml}.
\begin{lstlisting}[language=XML]
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>hr.fer.zemris</groupId>
  <artifactId>Prvi-programi</artifactId>
  <version>0.0.1-SNAPSHOT</version>
  <name>Prvi programi</name>
  <description>Prvi programi u Spark-u</description>
  <dependencies>
  	<dependency>
  		<groupId>org.apache.spark</groupId>
  		<artifactId>spark-core_2.10</artifactId>
  		<version>1.6.1</version>
  	</dependency>
  </dependencies>
</project>
\end{lstlisting}
\end{appendices}

\begin{sazetak}
Sažetak na hrvatskom jeziku.

\kljucnerijeci{Ključne riječi, odvojene zarezima.}
\end{sazetak}

% TODO: Navedite naslov na engleskom jeziku.
\engtitle{Title}
\begin{abstract}
Abstract.

\keywords{Keywords.}
\end{abstract}

\end{document}